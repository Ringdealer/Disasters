{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from io import StringIO\n",
    "import importlib\n",
    "import math\n",
    "import os\n",
    "import pdb\n",
    "import re\n",
    "import regex\n",
    "import sys \n",
    "\n",
    "# Third party imports\n",
    "import dateparser\n",
    "import reverse_geocoder as rg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Local application imports\n",
    "import mender_tools as mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the csv file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('blazes/fires.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set options to display all rows and columns in Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking out the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Cause', 'Coordinates', 'Date', 'Fuels Involved', 'Incident', 'Incident Type', 'Location', 'Perimeter Contained (%)', 'Personnel Involved', 'Fire Size (Acres)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing rows with all values missing and striping whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking total number of rows with all cells empty\n",
    "df.isnull().all(axis=1).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the rows with all cells empty\n",
    "df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting the index of the dataframe\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing and leading whitespaces\n",
    "df.loc[:,:] = df.applymap(lambda x: x.strip() if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Locate rows of duplicate data\n",
    "dups = df.duplicated()\n",
    "print(dups.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' In order to make a copy of the dataframe we need two different instances of the dataframe, if we don't do that any changes\n",
    "made to any of the variables that reference to dataframe will modify the other one. In that case we use the method copy().'''\n",
    "wildfire_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrange Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing column 'Fire Size (Acres)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy values of acres in column 'Personnel Involved' that pertain to column 'Fire Size (Acres)'\n",
    "wildfire_df = mt.emend_values(df, wildfire_df, 'Personnel Involved', 'Fire Size (Acres)', r'.*\\s*Acres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the string 'Acres' that comes along with the digits\n",
    "wildfire_df = mt.strip_symbol(wildfire_df, 'Fire Size (Acres)', 'Acres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string digits to integer values\n",
    "wildfire_df = mt.convert_to_int(wildfire_df, 'Fire Size (Acres)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Check for value types \n",
    "wildfire_df['Fire Size (Acres)'].apply(type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing column 'Perimeter Contained (%)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values in column 'Fire Size (Acres)' that belong to column 'Perimeter Contained (%)'\n",
    "wildfire_df = mt.emend_values(df, wildfire_df, 'Fire Size (Acres)', 'Perimeter Contained (%)', r'^\\d*[.]{0,1}\\d*\\s*%$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of '%' symbol\n",
    "wildfire_df = mt.strip_symbol(wildfire_df, 'Perimeter Contained (%)', '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float values to integer\n",
    "wildfire_df = mt.convert_to_int(wildfire_df, 'Perimeter Contained (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total of value types\n",
    "wildfire_df['Perimeter Contained (%)'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string values to NaN\n",
    "wildfire_df = mt.str_to_nan(wildfire_df, 'Perimeter Contained (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total of value types\n",
    "wildfire_df['Perimeter Contained (%)'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total of null values\n",
    "wildfire_df['Perimeter Contained (%)'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing column 'Personnel Involved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check elements type\n",
    "wildfire_df['Personnel Involved'].apply(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total value types\n",
    "wildfire_df['Personnel Involved'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total sum of null values\n",
    "wildfire_df['Personnel Involved'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string digits to int\n",
    "wildfire_df = mt.convert_to_int(wildfire_df, 'Personnel Involved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert no digits strings to NANs\n",
    "wildfire_df = mt.str_to_nan(wildfire_df, 'Personnel Involved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df = mt.convert_to_string(wildfire_df, 'Personnel Involved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column to 'Int64' to have a column both with integer and NAN values\n",
    "wildfire_df['Personnel Involved'] = wildfire_df['Personnel Involved'] .astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show value type for shown columns side by side\n",
    "wildfire_df[['Fire Size (Acres)','Personnel Involved','Perimeter Contained (%)']].applymap(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To finalize the numeric columns preparation we save the dataframe as a csv file\n",
    "wildfire_df.to_csv('blazes/fires_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrange Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Column 'Coordinates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file into a new dataframe\n",
    "wildf = pd.read_csv('blazes/fires_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe\n",
    "wildf_dfv2 = wildf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the values from column 'Location' to the corresponding cells in column 'Coordinates'\n",
    "wildf_dfv2 = mt.emend_values(df, wildf_dfv2, 'Location', 'Coordinates', r'-?\\d+\\.?\\d+\\s*latitude,?\\s*-?\\d+\\.?\\d+\\s*longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the values from column 'Cause' to the corresponding cells in column 'Coordinates'\n",
    "wildf_dfv2 = mt.emend_values(df, wildf_dfv2, 'Cause', 'Coordinates', r'-?\\d+\\.?\\d+\\s*latitude,?\\s*-?\\d+\\.?\\d+\\s*longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wildf_dfv2['Coordinates'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Latitude' with the values that go along with 'latitude' in column 'Coordinates'\n",
    "wildf_dfv2 = mt.create_new_col(wildf_dfv2, r'-?\\d+\\.?\\d+\\s*(?=latitude)', 'Coordinates', 'Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Longitude' with the values that go along with 'longitude' in column 'Coordinates'\n",
    "wildf_dfv2 = mt.create_new_col(wildf_dfv2, r'-?\\d+\\.?\\d+\\s*(?=longitude)', 'Coordinates', 'Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show value types totals\n",
    "wildf_dfv2['Latitude'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show empty strings totals\n",
    "(wildf_dfv2['Latitude'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empty strings with NaNs values in column 'Longitude'\n",
    "wildf_dfv2['Longitude'].replace(r'^\\s*$', np.nan, regex=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empty strings with NaNs values in column 'Latitude'\n",
    "wildf_dfv2['Latitude'].replace(r'^\\s*$', np.nan, regex=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show value types totals\n",
    "wildf_dfv2['Latitude'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show null values totals\n",
    "wildf_dfv2['Latitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to float in column 'Latitude'\n",
    "wildf_dfv2['Latitude'] = pd.to_numeric(wildf_dfv2['Latitude'], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to float in column 'Longitude'\n",
    "wildf_dfv2['Longitude'] = pd.to_numeric(wildf_dfv2['Longitude'], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column 'Coordinates'\n",
    "wildf_dfv2.drop(['Coordinates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Column 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the values from column 'Cause' to the corresponding cells in column 'Date'\n",
    "wildf_dfv2 = mt.emend_values(df, wildf_dfv2, 'Cause', 'Date', r'(\\d{2}:\\d{2}\\s?(AM|PM))$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove string 'approx.' from the string containing the day and hour\n",
    "wildf_dfv2 = mt.strip_symbol(wildf_dfv2, 'Date', 'approx.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date entries from 'Date' column to ISO format\n",
    "wildf_dfv2 = mt.convert_to_isodate(wildf_dfv2, 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show columns 'Date' and 'ISO Date' side by side\n",
    "wildf_dfv2.loc[:,['Date', 'ISO Date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column 'Date'\n",
    "wildf_dfv2.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Column 'Cause'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of strings of dates\n",
    "wildf_dfv2 = mt.strip_string(wildf_dfv2, 'Cause', r'-?\\d+\\.?\\d+\\s*latitude,?\\s*-?\\d+\\.?\\d+\\s*longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of strings of coordinates\n",
    "wildf_dfv2 = mt.strip_string(wildf_dfv2, 'Cause', r'(\\d{2}:\\d{2}\\s?(AM|PM))$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing and leading whitespaces\n",
    "wildf_dfv2.loc[:, 'Cause'] = wildf_dfv2.loc[:, 'Cause'].apply(lambda x: x.strip() if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty strings with NaN values\n",
    "wildf_dfv2['Cause'].replace(r'^\\s*$', np.nan, regex=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and populate set with causes of fire\n",
    "causes = set()\n",
    "for item in wildf_dfv2['Cause']:\n",
    "    if isinstance(item, str):\n",
    "        if item not in causes:\n",
    "            causes.add(item)\n",
    "print(causes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List causes of fire from set 'causes'\n",
    "i=1\n",
    "for item in causes:\n",
    "    print(i,'->',item)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad hoc function for replacing and fixing redundant values in column 'Cause'\n",
    "result = \"\"\n",
    "def is_match(pattern, x, word):\n",
    "    global result\n",
    "    if isinstance(x, str):\n",
    "        match = re.search(pattern, x)\n",
    "        if match:\n",
    "            result = x.replace(match.string, word)\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    return True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using function 'is_match' with a lambda function\n",
    "wildf_dfv2.loc[:, 'Cause'] = wildf_dfv2.loc\\\n",
    "[:, 'Cause'].apply(lambda x:x.replace(x, result) if\\\n",
    "is_match(r'Lightning', x, 'Lightning') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using function 'is_match' with a lambda function\n",
    "wildf_dfv2.loc[:, 'Cause'] = wildf_dfv2.loc\\\n",
    "[:, 'Cause'].apply(lambda x:x.replace(x, result)\\\n",
    "if is_match(r'Human', x, 'Human Caused') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using function 'is_match' with a lambda function\n",
    "wildf_dfv2.loc[:, 'Cause'] = wildf_dfv2.loc\\\n",
    "[:, 'Cause'].apply(lambda x:x.replace(x, result)\\\n",
    "                   if is_match(r'Unk[n]?own', x, 'Unknown') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildf_dfv2.loc[:, 'Cause'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating column Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the location given by latitude and longitude coordinates\n",
    "def get_location(coordinates):\n",
    "    return rg.search(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating column 'Region' based on coordinates data\n",
    "def create_region_col(df):\n",
    "    i = 0\n",
    "    for latitude, longitude in zip(wildf_dfv2['Latitude'], wildf_dfv2['Longitude']):        \n",
    "        if (not math.isnan(latitude) and not math.isnan(longitude)):\n",
    "           coordinates = (latitude, longitude)\n",
    "           location = get_location(coordinates)\n",
    "           df.at[i, 'Region'] = list(location[0].values())[3]\n",
    "           i += 1            \n",
    "        else:\n",
    "           i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Call to function create_region_col\n",
    "create_region_col(wildf_dfv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values after last call to create_region_col\n",
    "wildf_dfv2.loc[:,  'Region'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wildf_dfv2.loc[15:24, ['Location', 'Latitude', 'Longitude', 'Region']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildf_dfv21 = wildf_dfv2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wildf_dfv21['Region'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with US states names and their abbrevations\n",
    "us_abbrev_dic={'Alabama': 'AL', 'Alaska': 'AK', 'Arizona':'AZ', 'Arkansas':'AR',\n",
    "               'California': 'CA', 'Colorado':'CO', 'Connecticut':'CT', 'Delaware':'DE',\n",
    "               'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
    "               'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
    "               'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "               'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
    "               'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
    "               'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
    "               'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "               'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "               'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT',\n",
    "               'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV',\n",
    "               'Wisconsin': 'WI', 'Wyoming': 'WY'  \n",
    "              }\n",
    "st = us_abbrev_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad hoc function for completing states names in column 'Region' based on column 'Location' data\n",
    "def loc_to_state(df, col):\n",
    "    i=0\n",
    "    flag=0\n",
    "    list_count = 0\n",
    "    wordup = ''\n",
    "    for sentence in df[col]:\n",
    "        if not isinstance(df.at[i,'Region'], str):\n",
    "            if isinstance(sentence, str):\n",
    "                word_list = re.findall(r'\\w+', sentence)\n",
    "                word_list_len = len(word_list)\n",
    "                for word in word_list:\n",
    "                    list_count += 1\n",
    "                    if len(word)>2:\n",
    "                        wordup = word.upper()\n",
    "                    else:\n",
    "                        wordup = word\n",
    "                    for st_name, st_abbrev in st.items():\n",
    "                        upper_st = st_name.upper()\n",
    "                        if (wordup == upper_st or wordup == st_abbrev):\n",
    "                            df.at[i,'Region'] = st_name\n",
    "                            i+=1\n",
    "                            flag = 1\n",
    "                            break\n",
    "                    if (list_count == word_list_len and flag ==0):\n",
    "                        list_count = 0\n",
    "                        i+=1\n",
    "                    elif(flag == 1):\n",
    "                        list_count = 0\n",
    "                        flag = 0\n",
    "                        break\n",
    "            else:\n",
    "                i+=1\n",
    "        else:\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to function loc_to_state\n",
    "loc_to_state(wildf_dfv21, 'Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the rows of 'Location' that will be googled\n",
    "i = 0\n",
    "indexes = list()\n",
    "for item, name in zip(wildf_dfv21['Region'], wildf_dfv21['Location']):\n",
    "    if (isinstance(item, float) and not isinstance(name, float)):\n",
    "        indexes.append(wildf_dfv21.index[wildf_dfv21['Location'] == name].tolist())\n",
    "        print(indexes[i][0], '->', name)\n",
    "        i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with the last states with keys serving as dataframe corresponding indexes\n",
    "last_st = {20:'California', 23:'Colorado', 26: 'Arizona', 33: 'Arizona',\\\n",
    "          53: 'Oregon', 56: 'Arizona', 61: 'Idaho', 67: 'Nevada', 76: 'California',\\\n",
    "           78: 'California', 97: 'Arizona', 98: 'California'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set last missing states\n",
    "for key, values in last_st.items():\n",
    "        wildf_dfv21.at[key, 'Region'] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wildf_dfv21.loc[[12,40], ['Incident', 'Location', 'Region']].head(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildf_dfv21.at[12, 'Region'] = 'New Mexico'\n",
    "wildf_dfv21.at[40, 'Region'] ='California'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column 'Location'\n",
    "wildf_dfv21.drop(['Location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column 'Incident'\n",
    "wildf_dfv21.drop(['Incident'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to csv file\n",
    "wildf_dfv21.to_csv('blazes/fires_v3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Tweakings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file into a new dataframe\n",
    "wildf = pd.read_csv('blazes/fires_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "wildf_dfv3 = wildf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show selected columns where column 'Incident Type' is 'Burned Area Emergency Response'\n",
    "exclude = ['Latitude','Longitude', 'Fuels Involved', 'Region']\n",
    "wildf_dfv3.loc[wildf_dfv3['Incident Type'] == 'Burned Area Emergency Response', wildf_dfv3.columns.difference(exclude, sort=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildf_dfv3.drop(index=wildf_dfv3[wildf_dfv3['Incident Type'] == 'Burned Area Emergency Response'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking total number of rows with all cells empty\n",
    "wildf_dfv3.isnull().all(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the rows with all cells empty\n",
    "wildf_dfv3.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildf_dfv3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting float values to integers. When saving dataframe to csv int values are saved as float\n",
    "# wildf_dfv3[['Perimeter Contained (%)','Personnel Involved','Fire Size (Acres)']] = wildf_dfv3[['Perimeter Contained (%)','Personnel Involved','Fire Size (Acres)']].astype('Int64')\n",
    "# Or convert only 'Pesonnel involved' and 'Fire Size (Acres)' to integer values'\n",
    "wildf_dfv3[['Personnel Involved','Fire Size (Acres)']] = wildf_dfv3[['Personnel Involved','Fire Size (Acres)']].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final dataset\n",
    "exclude = ['Latitude','Longitude', 'Fuels Involved']\n",
    "wildf_dfv3.loc[:, wildf_dfv3.columns.difference(exclude, sort=False)].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildf_dfv3.to_csv('blazes/fires_v4.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addendum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with U.S states-capitals\n",
    "us_capital_dic={\n",
    "    'Alabama': 'Montgomery',\n",
    "    'Alaska': 'Juneau',\n",
    "    'Arizona':'Phoenix',\n",
    "    'Arkansas':'Little Rock',\n",
    "    'California': 'Sacramento',\n",
    "    'Colorado':'Denver',\n",
    "    'Connecticut':'Hartford',\n",
    "    'Delaware':'Dover',\n",
    "    'Florida': 'Tallahassee',\n",
    "    'Georgia': 'Atlanta',\n",
    "    'Hawaii': 'Honolulu',\n",
    "    'Idaho': 'Boise',\n",
    "    'Illinois': 'Springfield',\n",
    "    'Indiana': 'Indianapolis',\n",
    "    'Iowa': 'Des Monies',\n",
    "    'Kansas': 'Topeka',\n",
    "    'Kentucky': 'Frankfort',\n",
    "    'Louisiana': 'Baton Rouge',\n",
    "    'Maine': 'Augusta',\n",
    "    'Maryland': 'Annapolis',\n",
    "    'Massachusetts': 'Boston',\n",
    "    'Michigan': 'Lansing',\n",
    "    'Minnesota': 'St. Paul',\n",
    "    'Mississippi': 'Jackson',\n",
    "    'Missouri': 'Jefferson City',\n",
    "    'Montana': 'Helena',\n",
    "    'Nebraska': 'Lincoln',\n",
    "    'Nevada': 'Carson City',\n",
    "    'New Hampshire': 'Concord',\n",
    "    'New Jersey': 'Trenton',\n",
    "    'New Mexico': 'Santa Fe',\n",
    "    'New York': 'Albany',\n",
    "    'North Carolina': 'Raleigh',\n",
    "    'North Dakota': 'Bismarck',\n",
    "    'Ohio': 'Columbus',\n",
    "    'Oklahoma': 'Oklahoma City',\n",
    "    'Oregon': 'Salem',\n",
    "    'Pennsylvania': 'Harrisburg',\n",
    "    'Rhode Island': 'Providence',\n",
    "    'South Carolina': 'Columbia',\n",
    "    'South Dakoda': 'Pierre',\n",
    "    'Tennessee': 'Nashville',\n",
    "    'Texas': 'Austin',\n",
    "    'Utah': 'Salt Lake City',\n",
    "    'Vermont': 'Montpelier',\n",
    "    'Virginia': 'Richmond',\n",
    "    'Washington': 'Olympia',\n",
    "    'West Virginia': 'Charleston',\n",
    "    'Wisconsin': 'Madison',\n",
    "    'Wyoming': 'Cheyenne'  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing tips\n",
    "wildf_dfv2.loc[wildf_dfv2['Region'].isnull(), ['Location', 'Region']].head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
